{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y,coef= make_regression(n_samples=1000,n_features=16,n_targets=1,noise=1, coef=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y= Y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 16), (1000, 1), (16,))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,Y.shape,coef.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0067095827403914"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(reg.predict(X),Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用来做随机batch的模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiabetesDataset(Dataset):\n",
    "    def __init__(self, x_, y_):\n",
    "        self.len = x_.shape[0]\n",
    "        self.x_data = torch.from_numpy(x_)\n",
    "        # 这部很关键， 特征类型要求float类型\n",
    "        self.x_data = self.x_data.float()\n",
    "\n",
    "        self.y_data = torch.from_numpy(y_)\n",
    "        self.y_data = self.y_data.float()\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.x_data[item], self.y_data[item]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DiabetesDataset(X, Y)\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#网络结构\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size_, hidden_size_, num_classes_):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size_, hidden_size_) \n",
    "        self.fc2 = nn.Linear(hidden_size_, num_classes_)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(16, 8, 1)\n",
    "#损失函数\n",
    "criterion = nn.MSELoss(reduction='mean')\n",
    "#优化算法\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Step [1/10], Loss: 31712.3809\n",
      "Epoch [21/1000], Step [1/10], Loss: 7968.8398\n",
      "Epoch [41/1000], Step [1/10], Loss: 615.2706\n",
      "Epoch [61/1000], Step [1/10], Loss: 410.2522\n",
      "Epoch [81/1000], Step [1/10], Loss: 340.3250\n",
      "Epoch [101/1000], Step [1/10], Loss: 264.9956\n",
      "Epoch [121/1000], Step [1/10], Loss: 159.2020\n",
      "Epoch [141/1000], Step [1/10], Loss: 110.9754\n",
      "Epoch [161/1000], Step [1/10], Loss: 83.8748\n",
      "Epoch [181/1000], Step [1/10], Loss: 56.4725\n",
      "Epoch [201/1000], Step [1/10], Loss: 21.0028\n",
      "Epoch [221/1000], Step [1/10], Loss: 13.6329\n",
      "Epoch [241/1000], Step [1/10], Loss: 8.1904\n",
      "Epoch [261/1000], Step [1/10], Loss: 3.6308\n",
      "Epoch [281/1000], Step [1/10], Loss: 4.0657\n",
      "Epoch [301/1000], Step [1/10], Loss: 2.4795\n",
      "Epoch [321/1000], Step [1/10], Loss: 2.4859\n",
      "Epoch [341/1000], Step [1/10], Loss: 1.8292\n",
      "Epoch [361/1000], Step [1/10], Loss: 1.1391\n",
      "Epoch [381/1000], Step [1/10], Loss: 1.1895\n",
      "Epoch [401/1000], Step [1/10], Loss: 1.2428\n",
      "Epoch [421/1000], Step [1/10], Loss: 1.0511\n",
      "Epoch [441/1000], Step [1/10], Loss: 1.4060\n",
      "Epoch [461/1000], Step [1/10], Loss: 1.0450\n",
      "Epoch [481/1000], Step [1/10], Loss: 1.2469\n",
      "Epoch [501/1000], Step [1/10], Loss: 0.9519\n",
      "Epoch [521/1000], Step [1/10], Loss: 0.9404\n",
      "Epoch [541/1000], Step [1/10], Loss: 1.0905\n",
      "Epoch [561/1000], Step [1/10], Loss: 0.8626\n",
      "Epoch [581/1000], Step [1/10], Loss: 1.0517\n",
      "Epoch [601/1000], Step [1/10], Loss: 1.2133\n",
      "Epoch [621/1000], Step [1/10], Loss: 0.8925\n",
      "Epoch [641/1000], Step [1/10], Loss: 0.9847\n",
      "Epoch [661/1000], Step [1/10], Loss: 1.1773\n",
      "Epoch [681/1000], Step [1/10], Loss: 0.8552\n",
      "Epoch [701/1000], Step [1/10], Loss: 0.8282\n",
      "Epoch [721/1000], Step [1/10], Loss: 0.8911\n",
      "Epoch [741/1000], Step [1/10], Loss: 1.0297\n",
      "Epoch [761/1000], Step [1/10], Loss: 0.9696\n",
      "Epoch [781/1000], Step [1/10], Loss: 0.9215\n",
      "Epoch [801/1000], Step [1/10], Loss: 0.8645\n",
      "Epoch [821/1000], Step [1/10], Loss: 0.9416\n",
      "Epoch [841/1000], Step [1/10], Loss: 0.8797\n",
      "Epoch [861/1000], Step [1/10], Loss: 1.0385\n",
      "Epoch [881/1000], Step [1/10], Loss: 1.1508\n",
      "Epoch [901/1000], Step [1/10], Loss: 1.2387\n",
      "Epoch [921/1000], Step [1/10], Loss: 0.9969\n",
      "Epoch [941/1000], Step [1/10], Loss: 1.2439\n",
      "Epoch [961/1000], Step [1/10], Loss: 0.9917\n",
      "Epoch [981/1000], Step [1/10], Loss: 0.7670\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        # Reshape images to (batch_size, input_size)\n",
    "        x = x.reshape(-1, 16)\n",
    "        # Forward pass\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #输出中间信息\n",
    "        if i % 50 == 0 and epoch%20==0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存模型与运行模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "path = './a.pth'\n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[-3.6667, -5.3661, -0.7674, -0.4398, -4.8885,  0.4457, -4.2127, -5.0262,\n",
       "                        0.1182, -5.1086, -0.5638, -0.5699, -3.2498, -4.6512, -0.7648, -0.9245],\n",
       "                      [ 2.5073,  4.6040,  0.1939,  0.4286,  3.2740, -0.1376,  2.4669,  3.5374,\n",
       "                        0.3028,  3.0339,  0.1359,  0.4917,  2.3221,  4.0489, -0.0877,  0.2348],\n",
       "                      [-4.0278, -5.9198,  0.7995, -0.6522, -5.1610, -0.5550, -3.8845, -6.1311,\n",
       "                        0.7170, -5.0085,  0.1621, -0.2133, -4.4276, -5.2549,  0.0244,  0.6776],\n",
       "                      [ 3.0983,  4.1505, -0.6430,  0.7187,  3.9150,  0.5370,  2.6579,  4.4683,\n",
       "                       -0.4706,  3.7164, -0.2812, -0.0297,  3.3104,  3.7315, -0.0520, -0.5609],\n",
       "                      [ 3.1253,  4.3618, -0.3414,  0.0862,  3.8483,  0.2011,  3.3958,  4.8006,\n",
       "                       -0.3718,  3.6805,  0.0551,  0.5733,  3.0807,  3.8930, -0.0916, -0.2089],\n",
       "                      [ 2.8026,  4.1805,  0.6640,  0.4065,  3.8707, -0.3709,  3.3509,  3.8322,\n",
       "                       -0.1799,  3.9397,  0.3503,  0.3438,  2.4278,  3.6503,  0.6194,  0.7014],\n",
       "                      [ 2.2202,  4.1564,  0.0503,  0.1617,  3.8060, -0.1130,  2.5400,  4.1178,\n",
       "                        0.6720,  3.2643, -0.2515,  0.4936,  2.5649,  4.4694, -0.3962, -0.1934],\n",
       "                      [-3.3123, -5.8137, -0.1175, -0.3317, -4.9458,  0.1264, -3.5399, -5.4085,\n",
       "                       -0.8542, -4.0745,  0.3324, -0.7677, -3.2204, -5.8416,  0.6640,  0.1703]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([ 0.3939,  0.3512, -0.2401,  0.1812, -0.0554, -0.4323, -0.0061, -0.0713])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[-4.4310,  3.4656, -4.8740,  3.5277,  3.7976,  4.0542,  4.0329, -4.8551]])),\n",
       "             ('fc2.bias', tensor([0.0607]))])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看参数\n",
    "pargram = torch.load('./a.pth')\n",
    "pargram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.6667, -5.3661, -0.7674, -0.4398, -4.8885,  0.4457, -4.2127, -5.0262,\n",
       "          0.1182, -5.1086, -0.5638, -0.5699, -3.2498, -4.6512, -0.7648, -0.9245],\n",
       "        [ 2.5073,  4.6040,  0.1939,  0.4286,  3.2740, -0.1376,  2.4669,  3.5374,\n",
       "          0.3028,  3.0339,  0.1359,  0.4917,  2.3221,  4.0489, -0.0877,  0.2348],\n",
       "        [-4.0278, -5.9198,  0.7995, -0.6522, -5.1610, -0.5550, -3.8845, -6.1311,\n",
       "          0.7170, -5.0085,  0.1621, -0.2133, -4.4276, -5.2549,  0.0244,  0.6776],\n",
       "        [ 3.0983,  4.1505, -0.6430,  0.7187,  3.9150,  0.5370,  2.6579,  4.4683,\n",
       "         -0.4706,  3.7164, -0.2812, -0.0297,  3.3104,  3.7315, -0.0520, -0.5609],\n",
       "        [ 3.1253,  4.3618, -0.3414,  0.0862,  3.8483,  0.2011,  3.3958,  4.8006,\n",
       "         -0.3718,  3.6805,  0.0551,  0.5733,  3.0807,  3.8930, -0.0916, -0.2089],\n",
       "        [ 2.8026,  4.1805,  0.6640,  0.4065,  3.8707, -0.3709,  3.3509,  3.8322,\n",
       "         -0.1799,  3.9397,  0.3503,  0.3438,  2.4278,  3.6503,  0.6194,  0.7014],\n",
       "        [ 2.2202,  4.1564,  0.0503,  0.1617,  3.8060, -0.1130,  2.5400,  4.1178,\n",
       "          0.6720,  3.2643, -0.2515,  0.4936,  2.5649,  4.4694, -0.3962, -0.1934],\n",
       "        [-3.3123, -5.8137, -0.1175, -0.3317, -4.9458,  0.1264, -3.5399, -5.4085,\n",
       "         -0.8542, -4.0745,  0.3324, -0.7677, -3.2204, -5.8416,  0.6640,  0.1703]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pargram['fc1.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (fc1): Linear(in_features=16, out_features=8, bias=True)\n",
       "  (fc2): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载模型\n",
    "model = NeuralNet(16, 8, 1)\n",
    "model.load_state_dict(torch.load('./a.pth'))\n",
    "#必须调用model.eval()将dropout和batch normalization层设置为测试模式，不然会导致不一致的结果。\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#预测\n",
    "predicted = model(torch.from_numpy(X).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0164083893607927"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(predicted.detach().numpy(),Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "tianchi_metadata": {
   "competitions": [],
   "datasets": [],
   "description": "",
   "notebookId": "113326"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
