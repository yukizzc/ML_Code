{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = make_classification(n_samples = 1000,n_features = 16,n_classes = 5,n_informative = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y= Y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 16),\n",
       " (1000, 1),\n",
       " array([[ 2.41404011e+00, -3.01287593e-01,  2.28314573e+00,\n",
       "          4.46496263e-01, -3.25942430e+00,  1.07472666e+00,\n",
       "          6.91011224e-01,  1.06938957e+00,  3.16037213e-01,\n",
       "         -3.53390752e-02,  9.30444431e-01, -5.36243463e-01,\n",
       "          7.70201506e-01,  5.45843430e-02, -1.52371209e+00,\n",
       "         -2.94961235e-01],\n",
       "        [-1.55951757e+00,  1.14424361e+00,  2.88358232e-01,\n",
       "          2.44035013e-01,  2.93053260e+00, -1.24705713e+00,\n",
       "         -1.50666031e+00,  1.92551518e-01, -2.18125791e+00,\n",
       "          2.28717199e+00,  1.30473003e+00, -1.67987587e-02,\n",
       "          9.10420792e-01,  2.09629988e+00,  1.14286556e-01,\n",
       "          4.38250404e-01],\n",
       "        [ 2.54070229e+00, -5.82473265e-01,  2.81405150e-01,\n",
       "         -1.87853761e+00, -1.45703037e+00, -8.88682816e-01,\n",
       "         -2.09448133e+00, -3.90863085e-01,  3.85238016e+00,\n",
       "         -3.08969570e+00,  1.81046465e+00, -6.54977770e-01,\n",
       "          1.43543123e+00,  9.85475770e-01,  2.00158182e+00,\n",
       "          1.59639399e-01],\n",
       "        [ 6.70414858e-01, -2.88631920e-01, -8.21841834e-01,\n",
       "          1.24503704e+00,  7.52178578e-01,  1.57034210e+00,\n",
       "          5.00273765e-01,  1.31968740e-01,  1.00481348e+00,\n",
       "         -3.58080574e-01,  8.58502160e-01, -6.82440600e-01,\n",
       "          2.13721854e-01,  6.83450363e-01, -7.04495324e-01,\n",
       "         -7.04059036e-01],\n",
       "        [-8.54169474e-01, -7.13451968e-01, -5.22694185e+00,\n",
       "          1.00182842e+00, -1.97789456e-01,  4.23224184e-01,\n",
       "         -2.72355991e-01,  2.73080617e+00,  7.43077241e+00,\n",
       "         -2.01221677e+00, -1.78498234e-01, -6.32204599e-01,\n",
       "         -4.93632296e-01, -4.76107394e-01,  1.25972503e+00,\n",
       "          7.23362646e-02],\n",
       "        [ 1.05400291e+00, -1.89449754e-01, -1.00874830e+00,\n",
       "          1.10325622e+00, -4.50789928e-01,  8.49533979e-01,\n",
       "          8.71105079e-01,  1.15946860e+00, -5.61045252e-01,\n",
       "          2.47288282e+00, -1.55771822e-01,  5.71036727e-01,\n",
       "          4.57358131e-01, -1.47340408e-01, -3.71171448e+00,\n",
       "         -1.64194176e+00],\n",
       "        [-2.62845201e-01, -7.97047247e-01, -2.18291560e+00,\n",
       "         -1.12927713e+00,  9.63163062e-01, -7.07688498e-01,\n",
       "          3.58550023e+00, -2.26087535e+00,  9.26533897e-01,\n",
       "         -3.23947524e+00, -1.29733136e+00, -1.24599867e+00,\n",
       "         -1.66483618e+00, -1.15652239e+00,  3.36519101e-01,\n",
       "         -4.22267707e-01],\n",
       "        [ 1.02958830e+00, -6.65654630e-02, -1.37175523e-01,\n",
       "          8.03737354e-01,  2.20008654e-03, -5.87735958e-03,\n",
       "          1.20496015e+00,  4.41492854e-01, -1.42480926e-01,\n",
       "          6.41703839e-01, -1.70302044e+00,  9.21721068e-01,\n",
       "         -1.31285137e+00,  8.87895614e-01, -2.05192115e+00,\n",
       "          3.76379143e-01],\n",
       "        [-1.21338231e+00, -2.49158853e-02,  1.11962151e+00,\n",
       "          4.20860153e-01, -1.47733782e-01,  1.79024975e+00,\n",
       "          4.33657571e-01,  1.30862219e+00,  1.24593442e-01,\n",
       "         -1.38847105e-02,  1.29790368e+00,  7.46825909e-01,\n",
       "          3.72210103e-01, -5.19657935e-01,  1.08557142e+00,\n",
       "         -8.64195328e-01],\n",
       "        [-1.23635514e+00,  1.24321013e+00, -9.50336464e-01,\n",
       "          4.79485742e-01,  1.62733937e+00,  1.57633478e+00,\n",
       "         -5.11613870e-01, -1.31056663e+00,  1.03757559e+00,\n",
       "         -2.11412438e+00,  4.03507433e-01, -2.36258162e-01,\n",
       "         -1.36624486e+00, -1.54869513e+00,  2.77693491e+00,\n",
       "         -1.60301639e-01]]),\n",
       " array([[2],\n",
       "        [3],\n",
       "        [3],\n",
       "        [2],\n",
       "        [4],\n",
       "        [0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [1],\n",
       "        [4]]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,Y.shape,X[:10],Y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = SVC()\n",
    "reg.fit(X,Y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(reg.predict(X),Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用来做随机batch的模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiabetesDataset(Dataset):\n",
    "    def __init__(self, x_, y_):\n",
    "        self.len = x_.shape[0]\n",
    "        self.x_data = torch.from_numpy(x_)\n",
    "        # 这部很关键， 特征类型要求float类型\n",
    "        self.x_data = self.x_data.float()\n",
    "        # 多分类的标签必须要用LongTensor类型\n",
    "        self.y_data = torch.LongTensor(y_)\n",
    "\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.x_data[item], self.y_data[item]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DiabetesDataset(X, Y)\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=500, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#网络结构\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(16, 32) \n",
    "        self.fc2 = nn.Linear(32, 10)  \n",
    "        self.fc3 = nn.Linear(10, 5)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet()\n",
    "#损失函数\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "#优化算法\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Step [1/2], Loss: 0.0004\n",
      "Epoch [21/1000], Step [1/2], Loss: 0.0003\n",
      "Epoch [41/1000], Step [1/2], Loss: 0.0003\n",
      "Epoch [61/1000], Step [1/2], Loss: 0.0003\n",
      "Epoch [81/1000], Step [1/2], Loss: 0.0002\n",
      "Epoch [101/1000], Step [1/2], Loss: 0.0002\n",
      "Epoch [121/1000], Step [1/2], Loss: 0.0002\n",
      "Epoch [141/1000], Step [1/2], Loss: 0.0002\n",
      "Epoch [161/1000], Step [1/2], Loss: 0.0002\n",
      "Epoch [181/1000], Step [1/2], Loss: 0.0002\n",
      "Epoch [201/1000], Step [1/2], Loss: 0.0002\n",
      "Epoch [221/1000], Step [1/2], Loss: 0.0002\n",
      "Epoch [241/1000], Step [1/2], Loss: 0.0002\n",
      "Epoch [261/1000], Step [1/2], Loss: 0.0002\n",
      "Epoch [281/1000], Step [1/2], Loss: 0.0002\n",
      "Epoch [301/1000], Step [1/2], Loss: 0.0002\n",
      "Epoch [321/1000], Step [1/2], Loss: 0.0002\n",
      "Epoch [341/1000], Step [1/2], Loss: 0.0002\n",
      "Epoch [361/1000], Step [1/2], Loss: 0.0002\n",
      "Epoch [381/1000], Step [1/2], Loss: 0.0001\n",
      "Epoch [401/1000], Step [1/2], Loss: 0.0001\n",
      "Epoch [421/1000], Step [1/2], Loss: 0.0001\n",
      "Epoch [441/1000], Step [1/2], Loss: 0.0001\n",
      "Epoch [461/1000], Step [1/2], Loss: 0.0001\n",
      "Epoch [481/1000], Step [1/2], Loss: 0.0001\n",
      "Epoch [501/1000], Step [1/2], Loss: 0.0001\n",
      "Epoch [521/1000], Step [1/2], Loss: 0.0001\n",
      "Epoch [541/1000], Step [1/2], Loss: 0.0001\n",
      "Epoch [561/1000], Step [1/2], Loss: 0.0001\n",
      "Epoch [581/1000], Step [1/2], Loss: 0.0001\n",
      "Epoch [601/1000], Step [1/2], Loss: 0.0001\n",
      "Epoch [621/1000], Step [1/2], Loss: 0.0001\n",
      "Epoch [641/1000], Step [1/2], Loss: 0.0001\n",
      "Epoch [661/1000], Step [1/2], Loss: 0.0001\n",
      "Epoch [681/1000], Step [1/2], Loss: 0.0001\n",
      "Epoch [701/1000], Step [1/2], Loss: 0.0001\n",
      "Epoch [721/1000], Step [1/2], Loss: 0.0001\n",
      "Epoch [741/1000], Step [1/2], Loss: 0.0001\n",
      "Epoch [761/1000], Step [1/2], Loss: 0.0001\n",
      "Epoch [781/1000], Step [1/2], Loss: 0.0001\n",
      "Epoch [801/1000], Step [1/2], Loss: 0.0001\n",
      "Epoch [821/1000], Step [1/2], Loss: 0.0001\n",
      "Epoch [841/1000], Step [1/2], Loss: 0.0001\n",
      "Epoch [861/1000], Step [1/2], Loss: 0.0001\n",
      "Epoch [881/1000], Step [1/2], Loss: 0.0001\n",
      "Epoch [901/1000], Step [1/2], Loss: 0.0001\n",
      "Epoch [921/1000], Step [1/2], Loss: 0.0000\n",
      "Epoch [941/1000], Step [1/2], Loss: 0.0001\n",
      "Epoch [961/1000], Step [1/2], Loss: 0.0001\n",
      "Epoch [981/1000], Step [1/2], Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        # Reshape images to (batch_size, input_size)\n",
    "        x = x.reshape(-1, 16)\n",
    "        # Forward pass\n",
    "        outputs = model(x)\n",
    "        #扁平化成一维的\n",
    "        y = y.squeeze()\n",
    "        loss = criterion(outputs, y)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #输出中间信息\n",
    "        if i % 50 == 0 and epoch%20==0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model(torch.LongTensor(X).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测出来的结果要转换取每个数据最大值所在索引\n",
    "predicted_class = predicted.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.723"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predicted_class.detach().numpy(),Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
