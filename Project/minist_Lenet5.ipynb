{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import struct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解码文件的代码http://www.manongjc.com/article/5265.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_path= r'D:\\data_ML\\minist\\train-labels.idx1-ubyte'\n",
    "with open(train_labels_path, 'rb') as lpath:\n",
    "    # '>' denotes bigedian\n",
    "    # 'I' denotes unsigned char\n",
    "    magic, n = struct.unpack('>II', lpath.read(8))\n",
    "    #loaded = np.fromfile(lpath, dtype = np.uint8)\n",
    "    train_labels = np.fromfile(lpath, dtype = np.uint8).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_path= r'D:\\data_ML\\minist\\train-images.idx3-ubyte'\n",
    "with open(test_images_path , 'rb') as f:\n",
    "    magic, num, rows, cols = struct.unpack('>IIII', f.read(16))\n",
    "    loaded = np.fromfile(test_images_path, dtype = np.uint8)\n",
    "    # images start from the 16th bytes\n",
    "    train_images = loaded[16:].reshape(len(train_labels), 784).astype(np.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiabetesDataset(Dataset):\n",
    "    def __init__(self, x_, y_):\n",
    "        self.len = x_.shape[0]\n",
    "        self.x_data = torch.from_numpy(x_)\n",
    "        # 这部很关键， 特征类型要求float类型\n",
    "        self.x_data = self.x_data.float()\n",
    "        self.y_data = torch.LongTensor(y_)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.x_data[item], self.y_data[item]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DiabetesDataset(train_images, train_labels)\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=200, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#网络结构\n",
    "class Lenet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
    "        self.maxpool_1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv_2 = nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=0)\n",
    "        self.maxpool_2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0) \n",
    "        \n",
    "        self.fc1 = nn.Linear(32*4*4,28)\n",
    "        self.fc2 = nn.Linear(28,10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.shape[0],1,28,28)\n",
    "        out = self.conv_1(x)\n",
    "        out = self.maxpool_1(out)\n",
    "        out = self.conv_2(out)\n",
    "        out = self.maxpool_2(out)\n",
    "        # 运行时候后面线性层注释，然后调试看下卷积操作后维度时候多少，然后设计最后的线性层\n",
    "        out = out.reshape(out.shape[0],32*4*4)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试下维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = train_images[0:2].reshape(2,1,28,28)\n",
    "net = Lenet5()\n",
    "net(torch.from_numpy(a).float()).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = Lenet5().to(device)\n",
    "#损失函数\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "#优化算法\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [1/300], Loss: 0.0224\n",
      "Epoch [1/50], Step [101/300], Loss: 0.0710\n",
      "Epoch [1/50], Step [201/300], Loss: 0.0294\n",
      "Epoch [2/50], Step [1/300], Loss: 0.0032\n",
      "Epoch [2/50], Step [101/300], Loss: 0.0333\n",
      "Epoch [2/50], Step [201/300], Loss: 0.0745\n",
      "Epoch [3/50], Step [1/300], Loss: 0.0302\n",
      "Epoch [3/50], Step [101/300], Loss: 0.0250\n",
      "Epoch [3/50], Step [201/300], Loss: 0.0437\n",
      "Epoch [4/50], Step [1/300], Loss: 0.0119\n",
      "Epoch [4/50], Step [101/300], Loss: 0.0011\n",
      "Epoch [4/50], Step [201/300], Loss: 0.0285\n",
      "Epoch [5/50], Step [1/300], Loss: 0.0130\n",
      "Epoch [5/50], Step [101/300], Loss: 0.0187\n",
      "Epoch [5/50], Step [201/300], Loss: 0.0188\n",
      "Epoch [6/50], Step [1/300], Loss: 0.0206\n",
      "Epoch [6/50], Step [101/300], Loss: 0.0308\n",
      "Epoch [6/50], Step [201/300], Loss: 0.0033\n",
      "Epoch [7/50], Step [1/300], Loss: 0.1014\n",
      "Epoch [7/50], Step [101/300], Loss: 0.0068\n",
      "Epoch [7/50], Step [201/300], Loss: 0.0009\n",
      "Epoch [8/50], Step [1/300], Loss: 0.0072\n",
      "Epoch [8/50], Step [101/300], Loss: 0.0056\n",
      "Epoch [8/50], Step [201/300], Loss: 0.0070\n",
      "Epoch [9/50], Step [1/300], Loss: 0.0402\n",
      "Epoch [9/50], Step [101/300], Loss: 0.1010\n",
      "Epoch [9/50], Step [201/300], Loss: 0.0114\n",
      "Epoch [10/50], Step [1/300], Loss: 0.1285\n",
      "Epoch [10/50], Step [101/300], Loss: 0.0099\n",
      "Epoch [10/50], Step [201/300], Loss: 0.0474\n",
      "Epoch [11/50], Step [1/300], Loss: 0.0186\n",
      "Epoch [11/50], Step [101/300], Loss: 0.0473\n",
      "Epoch [11/50], Step [201/300], Loss: 0.0019\n",
      "Epoch [12/50], Step [1/300], Loss: 0.0143\n",
      "Epoch [12/50], Step [101/300], Loss: 0.0208\n",
      "Epoch [12/50], Step [201/300], Loss: 0.0011\n",
      "Epoch [13/50], Step [1/300], Loss: 0.0031\n",
      "Epoch [13/50], Step [101/300], Loss: 0.0027\n",
      "Epoch [13/50], Step [201/300], Loss: 0.0070\n",
      "Epoch [14/50], Step [1/300], Loss: 0.0008\n",
      "Epoch [14/50], Step [101/300], Loss: 0.0168\n",
      "Epoch [14/50], Step [201/300], Loss: 0.0000\n",
      "Epoch [15/50], Step [1/300], Loss: 0.0024\n",
      "Epoch [15/50], Step [101/300], Loss: 0.0304\n",
      "Epoch [15/50], Step [201/300], Loss: 0.1389\n",
      "Epoch [16/50], Step [1/300], Loss: 0.0010\n",
      "Epoch [16/50], Step [101/300], Loss: 0.0143\n",
      "Epoch [16/50], Step [201/300], Loss: 0.0007\n",
      "Epoch [17/50], Step [1/300], Loss: 0.0828\n",
      "Epoch [17/50], Step [101/300], Loss: 0.0100\n",
      "Epoch [17/50], Step [201/300], Loss: 0.0214\n",
      "Epoch [18/50], Step [1/300], Loss: 0.0023\n",
      "Epoch [18/50], Step [101/300], Loss: 0.0001\n",
      "Epoch [18/50], Step [201/300], Loss: 0.0141\n",
      "Epoch [19/50], Step [1/300], Loss: 0.0404\n",
      "Epoch [19/50], Step [101/300], Loss: 0.0055\n",
      "Epoch [19/50], Step [201/300], Loss: 0.0001\n",
      "Epoch [20/50], Step [1/300], Loss: 0.0046\n",
      "Epoch [20/50], Step [101/300], Loss: 0.0517\n",
      "Epoch [20/50], Step [201/300], Loss: 0.0409\n",
      "Epoch [21/50], Step [1/300], Loss: 0.0363\n",
      "Epoch [21/50], Step [101/300], Loss: 0.0001\n",
      "Epoch [21/50], Step [201/300], Loss: 0.0403\n",
      "Epoch [22/50], Step [1/300], Loss: 0.0004\n",
      "Epoch [22/50], Step [101/300], Loss: 0.0017\n",
      "Epoch [22/50], Step [201/300], Loss: 0.0657\n",
      "Epoch [23/50], Step [1/300], Loss: 0.0095\n",
      "Epoch [23/50], Step [101/300], Loss: 0.0009\n",
      "Epoch [23/50], Step [201/300], Loss: 0.0058\n",
      "Epoch [24/50], Step [1/300], Loss: 0.0026\n",
      "Epoch [24/50], Step [101/300], Loss: 0.0103\n",
      "Epoch [24/50], Step [201/300], Loss: 0.0021\n",
      "Epoch [25/50], Step [1/300], Loss: 0.0018\n",
      "Epoch [25/50], Step [101/300], Loss: 0.0030\n",
      "Epoch [25/50], Step [201/300], Loss: 0.0003\n",
      "Epoch [26/50], Step [1/300], Loss: 0.0026\n",
      "Epoch [26/50], Step [101/300], Loss: 0.0133\n",
      "Epoch [26/50], Step [201/300], Loss: 0.0130\n",
      "Epoch [27/50], Step [1/300], Loss: 0.0083\n",
      "Epoch [27/50], Step [101/300], Loss: 0.0158\n",
      "Epoch [27/50], Step [201/300], Loss: 0.0000\n",
      "Epoch [28/50], Step [1/300], Loss: 0.0484\n",
      "Epoch [28/50], Step [101/300], Loss: 0.0060\n",
      "Epoch [28/50], Step [201/300], Loss: 0.0112\n",
      "Epoch [29/50], Step [1/300], Loss: 0.0004\n",
      "Epoch [29/50], Step [101/300], Loss: 0.0658\n",
      "Epoch [29/50], Step [201/300], Loss: 0.0003\n",
      "Epoch [30/50], Step [1/300], Loss: 0.0435\n",
      "Epoch [30/50], Step [101/300], Loss: 0.0000\n",
      "Epoch [30/50], Step [201/300], Loss: 0.0291\n",
      "Epoch [31/50], Step [1/300], Loss: 0.0183\n",
      "Epoch [31/50], Step [101/300], Loss: 0.0155\n",
      "Epoch [31/50], Step [201/300], Loss: 0.0000\n",
      "Epoch [32/50], Step [1/300], Loss: 0.0603\n",
      "Epoch [32/50], Step [101/300], Loss: 0.0177\n",
      "Epoch [32/50], Step [201/300], Loss: 0.0957\n",
      "Epoch [33/50], Step [1/300], Loss: 0.1403\n",
      "Epoch [33/50], Step [101/300], Loss: 0.0164\n",
      "Epoch [33/50], Step [201/300], Loss: 0.0321\n",
      "Epoch [34/50], Step [1/300], Loss: 0.0006\n",
      "Epoch [34/50], Step [101/300], Loss: 0.0448\n",
      "Epoch [34/50], Step [201/300], Loss: 0.0010\n",
      "Epoch [35/50], Step [1/300], Loss: 0.0000\n",
      "Epoch [35/50], Step [101/300], Loss: 0.0097\n",
      "Epoch [35/50], Step [201/300], Loss: 0.0000\n",
      "Epoch [36/50], Step [1/300], Loss: 0.0014\n",
      "Epoch [36/50], Step [101/300], Loss: 0.0717\n",
      "Epoch [36/50], Step [201/300], Loss: 0.0042\n",
      "Epoch [37/50], Step [1/300], Loss: 0.0419\n",
      "Epoch [37/50], Step [101/300], Loss: 0.0020\n",
      "Epoch [37/50], Step [201/300], Loss: 0.0483\n",
      "Epoch [38/50], Step [1/300], Loss: 0.0000\n",
      "Epoch [38/50], Step [101/300], Loss: 0.0026\n",
      "Epoch [38/50], Step [201/300], Loss: 0.0472\n",
      "Epoch [39/50], Step [1/300], Loss: 0.0172\n",
      "Epoch [39/50], Step [101/300], Loss: 0.0004\n",
      "Epoch [39/50], Step [201/300], Loss: 0.0854\n",
      "Epoch [40/50], Step [1/300], Loss: 0.0163\n",
      "Epoch [40/50], Step [101/300], Loss: 0.0002\n",
      "Epoch [40/50], Step [201/300], Loss: 0.0001\n",
      "Epoch [41/50], Step [1/300], Loss: 0.0852\n",
      "Epoch [41/50], Step [101/300], Loss: 0.0023\n",
      "Epoch [41/50], Step [201/300], Loss: 0.0079\n",
      "Epoch [42/50], Step [1/300], Loss: 0.0098\n",
      "Epoch [42/50], Step [101/300], Loss: 0.0000\n",
      "Epoch [42/50], Step [201/300], Loss: 0.1565\n",
      "Epoch [43/50], Step [1/300], Loss: 0.0120\n",
      "Epoch [43/50], Step [101/300], Loss: 0.0380\n",
      "Epoch [43/50], Step [201/300], Loss: 0.0096\n",
      "Epoch [44/50], Step [1/300], Loss: 0.0006\n",
      "Epoch [44/50], Step [101/300], Loss: 0.0218\n",
      "Epoch [44/50], Step [201/300], Loss: 0.0002\n",
      "Epoch [45/50], Step [1/300], Loss: 0.0249\n",
      "Epoch [45/50], Step [101/300], Loss: 0.0000\n",
      "Epoch [45/50], Step [201/300], Loss: 0.0001\n",
      "Epoch [46/50], Step [1/300], Loss: 0.0559\n",
      "Epoch [46/50], Step [101/300], Loss: 0.0000\n",
      "Epoch [46/50], Step [201/300], Loss: 0.0003\n",
      "Epoch [47/50], Step [1/300], Loss: 0.0464\n",
      "Epoch [47/50], Step [101/300], Loss: 0.1579\n",
      "Epoch [47/50], Step [201/300], Loss: 0.0866\n",
      "Epoch [48/50], Step [1/300], Loss: 0.0000\n",
      "Epoch [48/50], Step [101/300], Loss: 0.0173\n",
      "Epoch [48/50], Step [201/300], Loss: 0.0360\n",
      "Epoch [49/50], Step [1/300], Loss: 0.0029\n",
      "Epoch [49/50], Step [101/300], Loss: 0.0559\n",
      "Epoch [49/50], Step [201/300], Loss: 0.0023\n",
      "Epoch [50/50], Step [1/300], Loss: 0.0192\n",
      "Epoch [50/50], Step [101/300], Loss: 0.0245\n",
      "Epoch [50/50], Step [201/300], Loss: 0.0100\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(x)\n",
    "        #扁平化成一维的\n",
    "        y = y.squeeze()\n",
    "        loss = criterion(outputs, y)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #输出中间信息\n",
    "        if i % 100 == 0 :\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "path = './ft.pth'\n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lenet5(\n",
       "  (conv_1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (maxpool_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv_2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (maxpool_2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=512, out_features=28, bias=True)\n",
       "  (fc2): Linear(in_features=28, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载模型,模型和数据还是要放到cpu上去，全量的数据放gpu显存放不下\n",
    "model = Lenet5().to(torch.device('cpu'))\n",
    "model.load_state_dict(torch.load('./ft.pth'))\n",
    "#必须调用model.eval()将dropout和batch normalization层设置为测试模式，不然会导致不一致的结果。\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model(torch.LongTensor(train_images).float().to(torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class = predicted.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9963666666666666"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predicted_class.cpu().detach().numpy(),train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
